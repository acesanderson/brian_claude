[headwater0:python3* 1:docker- 2:python3  3:bash                                                                    % | 14:19 2026-02-06
                             │        device=device)                                                      │
                             ╰────────────────────────────────────────────────────────────────────────────╯                                                           RuntimeError: The expanded size of the tensor (520) must match the existing
                             size (514) at non-singleton dimension 1.  Target sizes: [1, 520].  Tensor                                                                sizes: [1, 514]
                    INFO     INFO:httpx:HTTP Request: POST                                                          httpx:_client.py:1740                             http://172.16.0.4:8001/api/v2/tenants/default_tenant/databases/default_database/collec
                             tions/80b061df-1499-48e6-bd32-f29096b4e183/query "HTTP/1.1 200 OK"                                          ------------------------------------------------------------------------
Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 467.70it/s]Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 755.73it/s]
If you want to use `XLMRobertaLMHeadModel` as a standalone, add `is_decoder=True.`
Some weights of XLMRobertaForCausalLM were not initialized from the model checkpoint at BAAI/bge-reranker-large and are newly initialized: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.

