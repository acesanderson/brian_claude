from __future__ import annotations

import html
import json
import re

import requests
from bs4 import BeautifulSoup


def get_topics(url: str) -> list[tuple[str, str]]:
    """Extract unique topic names and URLs from AMA topics page."""
    response = requests.get(url)
    response.raise_for_status()

    soup = BeautifulSoup(response.text, "html.parser")

    # Use dict to maintain order and deduplicate by URL
    topics = {}
    for p in soup.find_all("p", class_="has-blue-700-color"):
        link = p.find("a")
        if link and link.get("href", "").startswith("https://www.ama.org/topics/"):
            topic_name = link.get_text(strip=True)
            topic_url = link["href"]
            topics[topic_url] = topic_name

    return [(name, url) for url, name in topics.items()]


def get_courses_from_topic(topic_url: str) -> list[dict]:
    """Extract basic course info from a topic page."""
    response = requests.get(topic_url)
    response.raise_for_status()

    soup = BeautifulSoup(response.text, "html.parser")

    # Find the hidden input with JSON data
    archive_input = soup.find("input", {"id": "archive-posts"})
    if not archive_input:
        return []

    # Decode the HTML entities and parse JSON
    json_data = html.unescape(archive_input.get("value", ""))
    posts = json.loads(json_data)

    courses = []
    for post in posts:
        post_type = post.get("post_type")
        post_name = post.get("post_name")

        # Construct proper URL based on post type
        if post_type == "ama_event":
            url = f"https://www.ama.org/events/virtual-training/{post_name}/"
        elif post_type == "ama_courses":
            url = f"https://www.ama.org/on-demand/{post_name}/"
        else:
            url = post.get("guid", "")

        course = {
            "id": post.get("ID"),
            "title": post.get("post_title"),
            "url": url,
            "type": "Virtual Training" if post_type == "ama_event" else "On-Demand Course",
        }
        courses.append(course)

    return courses


def get_course_details(course_url: str) -> dict:
    """Scrape detailed metadata from a course page."""
    response = requests.get(course_url)
    response.raise_for_status()

    soup = BeautifulSoup(response.text, "html.parser")

    details = {}

    # Extract datetime from time tag
    time_tag = soup.find("time")
    if time_tag:
        details["datetime"] = time_tag.get_text(strip=True)

    # Extract duration/level (looks for "Online | X Hours" or "Beginner | X Hours")
    for p in soup.find_all("p"):
        text = p.get_text(strip=True)
        if "|" in text and ("Hours" in text or "Modules" in text):
            details["duration_info"] = text
            # Extract level if present
            if any(level in text for level in ["Beginner", "Intermediate", "Advanced"]):
                for level in ["Beginner", "Intermediate", "Advanced"]:
                    if level in text:
                        details["level"] = level
                        break
            break

    # Extract prices
    prices = {}
    price_elements = soup.find_all(class_="woocommerce-Price-amount")
    for idx, price_elem in enumerate(price_elements[:4]):  # Limit to first 4 prices
        parent = price_elem.find_parent()
        if parent:
            # Look for label in previous siblings
            label_elem = parent.find_previous("span")
            if label_elem:
                label = label_elem.get_text(strip=True)
                price = price_elem.get_text(strip=True)
                # Clean up label
                if label and label != "$" and len(label) < 50:
                    if "Member" in label and "Non" not in label:
                        label = "Member"
                    elif "Non-Member" in label:
                        label = "Non-Member"
                    prices[label] = price
    if prices:
        details["pricing"] = prices

    # Extract instructor (look for common patterns)
    for heading in soup.find_all(["h3", "h4", "strong"]):
        text = heading.get_text(strip=True)
        if any(word in text.lower() for word in ["instructor", "speaker", "facilitator", "taught by"]):
            # Get next sibling or parent's next sibling
            next_elem = heading.find_next(["p", "div"])
            if next_elem:
                instructor = next_elem.get_text(strip=True)
                if instructor and len(instructor) < 200:
                    details["instructor"] = instructor
                    break

    # Extract CE credits (avoid script tags)
    for elem in soup.find_all(string=re.compile(r"(\d+)\s*(CEU|Continuing Education Unit)")):
        # Skip if inside script or style tags
        if elem.parent.name not in ["script", "style"]:
            parent_text = elem.parent.get_text(strip=True)
            # Extract just the CEU sentence
            if len(parent_text) < 300:
                details["ce_credits"] = parent_text
                break

    # Extract description from meta tag
    meta_desc = soup.find("meta", {"name": "description"})
    if meta_desc:
        details["description"] = meta_desc.get("content", "")

    # Extract target audience
    for heading in soup.find_all(["h2", "h3"]):
        text = heading.get_text(strip=True)
        if "who should" in text.lower() or "target audience" in text.lower():
            next_elem = heading.find_next(["p", "ul", "div"])
            if next_elem:
                audience = next_elem.get_text(strip=True)
                if audience and len(audience) < 500:
                    details["target_audience"] = audience
                    break

    return details


if __name__ == "__main__":
    url = "https://www.ama.org/topics/"

    print("Getting topics...\n")
    topics = get_topics(url)

    print(f"Found {len(topics)} unique topics:\n")
    for i, (name, topic_url) in enumerate(topics, 1):
        print(f"{i}. {name}")

    # Get courses from first topic
    if topics:
        first_topic_name, first_topic_url = topics[0]
        print(f"\n\n{'=' * 80}")
        print(f"Courses from: {first_topic_name}")
        print("=" * 80 + "\n")

        courses = get_courses_from_topic(first_topic_url)
        print(f"Found {len(courses)} courses on first page\n")

        # Get details for first few courses
        for i, course in enumerate(courses[:5], 1):
            print(f"{i}. {course['title']}")
            print(f"   Type: {course['type']}")
            print(f"   URL: {course['url']}")

            try:
                details = get_course_details(course["url"])

                if details.get("datetime"):
                    print(f"   Date/Time: {details['datetime']}")
                if details.get("duration_info"):
                    print(f"   Duration: {details['duration_info']}")
                if details.get("level"):
                    print(f"   Level: {details['level']}")
                if details.get("instructor"):
                    print(f"   Instructor: {details['instructor']}")
                if details.get("target_audience"):
                    audience = details['target_audience']
                    if len(audience) > 100:
                        audience = audience[:100] + "..."
                    print(f"   Audience: {audience}")
                if details.get("ce_credits"):
                    print(f"   CE Credits: {details['ce_credits']}")
                if details.get("pricing"):
                    pricing_str = ", ".join([f"{label}: {price}" for label, price in details["pricing"].items()])
                    print(f"   Pricing: {pricing_str}")
                if details.get("description"):
                    desc = details['description']
                    if len(desc) > 150:
                        desc = desc[:150] + "..."
                    print(f"   Description: {desc}")

            except Exception as e:
                print(f"   Error: {e}")

            print()
