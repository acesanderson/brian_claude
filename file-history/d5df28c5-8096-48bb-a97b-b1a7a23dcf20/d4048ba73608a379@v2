from __future__ import annotations

import csv
import re
import time
from datetime import datetime

import requests
from bs4 import BeautifulSoup


# Browser headers to bypass CloudFront protection
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
}

BASE_URL = "https://academy.astronomer.io"


def fetch_page(url: str) -> BeautifulSoup:
    """Fetch and parse a page with proper headers."""
    response = requests.get(url, headers=HEADERS)
    response.raise_for_status()
    time.sleep(1)  # Be respectful
    return BeautifulSoup(response.text, "html.parser")


def get_learning_paths(soup: BeautifulSoup) -> list[dict]:
    """Extract learning path names and URLs from homepage."""
    paths = []

    # Find all links that start with /path/
    for link in soup.find_all("a", href=re.compile(r"^/path/[^/]+$")):
        path_url = link.get("href")
        # Get the path name from the link text or title
        path_name = link.get_text(strip=True)

        if path_url and path_url not in [p["url"] for p in paths]:
            paths.append({
                "name": path_name if path_name else path_url.split("/")[-1].replace("-", " ").title(),
                "url": f"{BASE_URL}{path_url}"
            })

    return paths


def get_courses_from_path(path_url: str) -> list[dict]:
    """Extract all courses from a learning path page."""
    soup = fetch_page(path_url)
    courses = []

    # Find course links within this path
    path_slug = path_url.split("/path/")[-1]
    for link in soup.find_all("a", href=re.compile(rf"^/path/{path_slug}/[^/]+$")):
        course_url = link.get("href")
        course_title = link.get_text(strip=True)

        if course_url and course_url not in [c["url"] for c in courses]:
            courses.append({
                "title": course_title,
                "url": f"{BASE_URL}{course_url}",
                "path": path_slug
            })

    return courses


def get_course_details(course_url: str) -> dict:
    """Scrape detailed metadata from a course page."""
    soup = fetch_page(course_url)
    details = {}

    # Extract title
    title_tag = soup.find("h1")
    if title_tag:
        details["title"] = title_tag.get_text(strip=True)

    # Extract description
    meta_desc = soup.find("meta", {"name": "description"})
    if meta_desc:
        details["description"] = meta_desc.get("content", "")

    # Look for duration/time estimate
    for elem in soup.find_all(["span", "div", "p"]):
        text = elem.get_text(strip=True)
        if re.search(r"\d+\s*(min|hour|hr)", text, re.IGNORECASE):
            details["duration"] = text
            break

    # Look for level
    for elem in soup.find_all(["span", "div", "p"]):
        text = elem.get_text(strip=True)
        if any(level in text for level in ["Beginner", "Intermediate", "Advanced"]):
            details["level"] = text
            break

    # Price (likely free for Astronomer Academy)
    details["price"] = "Free"

    return details


def export_to_csv(courses_data: list[dict], filename: str) -> None:
    """Export course data to CSV."""
    if not courses_data:
        print("No courses to export")
        return

    fieldnames = [
        "provider",
        "title",
        "url",
        "description",
        "duration",
        "level",
        "format",
        "price",
        "category",
        "learning_path",
        "date_scraped",
    ]

    with open(filename, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()

        for course in courses_data:
            writer.writerow({
                "provider": "Astronomer Academy",
                "title": course.get("title", ""),
                "url": course.get("url", ""),
                "description": course.get("description", ""),
                "duration": course.get("duration", ""),
                "level": course.get("level", ""),
                "format": "On-Demand",
                "price": course.get("price", "Free"),
                "category": "Apache Airflow / Data Engineering",
                "learning_path": course.get("path", ""),
                "date_scraped": datetime.now().strftime("%Y-%m-%d"),
            })

    print(f"✓ Exported {len(courses_data)} courses to {filename}")


if __name__ == "__main__":
    print("Scraping Astronomer Academy...")
    print("=" * 80)

    # Step 1: Get homepage and find learning paths
    print("\n[1/3] Discovering learning paths...")
    homepage = fetch_page(BASE_URL)
    paths = get_learning_paths(homepage)
    print(f"Found {len(paths)} learning paths")

    # Step 2: Get courses from each path
    print("\n[2/3] Extracting courses from each path...")
    all_courses = []
    for i, path in enumerate(paths, 1):
        print(f"  [{i}/{len(paths)}] {path['name']}...")
        try:
            courses = get_courses_from_path(path["url"])
            all_courses.extend(courses)
            print(f"      → Found {len(courses)} courses")
        except Exception as e:
            print(f"      → Error: {e}")

    print(f"\nTotal courses found: {len(all_courses)}")

    # Step 3: Get detailed metadata for each course
    print("\n[3/3] Fetching course details...")
    for i, course in enumerate(all_courses, 1):
        print(f"  [{i}/{len(all_courses)}] {course['title'][:60]}...")
        try:
            details = get_course_details(course["url"])
            course.update(details)
        except Exception as e:
            print(f"      → Error: {e}")

    # Export results
    print("\n" + "=" * 80)
    export_to_csv(all_courses, "astronomer_catalog.csv")

    # Show preview
    print("\nPreview of first 3 courses:")
    print("=" * 80)
    for i, course in enumerate(all_courses[:3], 1):
        print(f"\n{i}. {course['title']}")
        print(f"   Path: {course.get('path', 'N/A')}")
        print(f"   URL: {course['url']}")
        if course.get("description"):
            desc = course['description']
            if len(desc) > 100:
                desc = desc[:100] + "..."
            print(f"   Description: {desc}")
        if course.get("duration"):
            print(f"   Duration: {course['duration']}")
