from __future__ import annotations

import csv
import html
import json
import re

import requests
from bs4 import BeautifulSoup


def get_topics(url: str) -> list[tuple[str, str]]:
    """Extract unique topic names and URLs from AMA topics page."""
    response = requests.get(url)
    response.raise_for_status()

    soup = BeautifulSoup(response.text, "html.parser")

    # Use dict to maintain order and deduplicate by URL
    topics = {}
    for p in soup.find_all("p", class_="has-blue-700-color"):
        link = p.find("a")
        if link and link.get("href", "").startswith("https://www.ama.org/topics/"):
            topic_name = link.get_text(strip=True)
            topic_url = link["href"]
            topics[topic_url] = topic_name

    return [(name, url) for url, name in topics.items()]


def get_courses_from_topic(topic_url: str) -> list[dict]:
    """Extract basic course info from a topic page."""
    response = requests.get(topic_url)
    response.raise_for_status()

    soup = BeautifulSoup(response.text, "html.parser")

    # Find the hidden input with JSON data
    archive_input = soup.find("input", {"id": "archive-posts"})
    if not archive_input:
        return []

    # Decode the HTML entities and parse JSON
    json_data = html.unescape(archive_input.get("value", ""))
    posts = json.loads(json_data)

    courses = []
    for post in posts:
        post_type = post.get("post_type")
        post_name = post.get("post_name")

        # Construct proper URL based on post type
        if post_type == "ama_event":
            url = f"https://www.ama.org/events/virtual-training/{post_name}/"
        elif post_type == "ama_courses":
            url = f"https://www.ama.org/on-demand/{post_name}/"
        else:
            url = post.get("guid", "")

        course = {
            "id": post.get("ID"),
            "title": post.get("post_title"),
            "url": url,
            "type": "Virtual Training" if post_type == "ama_event" else "On-Demand Course",
        }
        courses.append(course)

    return courses


def get_course_details(course_url: str) -> dict:
    """Scrape detailed metadata from a course page."""
    response = requests.get(course_url)
    response.raise_for_status()

    soup = BeautifulSoup(response.text, "html.parser")

    details = {}

    # Extract datetime from time tag
    time_tag = soup.find("time")
    if time_tag:
        details["datetime"] = time_tag.get_text(strip=True)

    # Extract duration/level (looks for "Online | X Hours" or "Beginner | X Hours")
    for p in soup.find_all("p"):
        text = p.get_text(strip=True)
        if "|" in text and ("Hours" in text or "Modules" in text):
            details["duration_info"] = text
            # Extract level if present
            if any(level in text for level in ["Beginner", "Intermediate", "Advanced"]):
                for level in ["Beginner", "Intermediate", "Advanced"]:
                    if level in text:
                        details["level"] = level
                        break
            break

    # Extract prices
    prices = {}
    price_elements = soup.find_all(class_="woocommerce-Price-amount")
    for idx, price_elem in enumerate(price_elements[:4]):  # Limit to first 4 prices
        parent = price_elem.find_parent()
        if parent:
            # Look for label in previous siblings
            label_elem = parent.find_previous("span")
            if label_elem:
                label = label_elem.get_text(strip=True)
                price = price_elem.get_text(strip=True)
                # Clean up label
                if label and label != "$" and len(label) < 50:
                    if "Member" in label and "Non" not in label:
                        label = "Member"
                    elif "Non-Member" in label:
                        label = "Non-Member"
                    prices[label] = price
    if prices:
        details["pricing"] = prices

    # Extract instructor (look for common patterns)
    for heading in soup.find_all(["h3", "h4", "strong"]):
        text = heading.get_text(strip=True)
        if any(word in text.lower() for word in ["instructor", "speaker", "facilitator", "taught by"]):
            # Get next sibling or parent's next sibling
            next_elem = heading.find_next(["p", "div"])
            if next_elem:
                instructor = next_elem.get_text(strip=True)
                if instructor and len(instructor) < 200:
                    details["instructor"] = instructor
                    break

    # Extract CE credits (avoid script tags)
    for elem in soup.find_all(string=re.compile(r"(\d+)\s*(CEU|Continuing Education Unit)")):
        # Skip if inside script or style tags
        if elem.parent.name not in ["script", "style"]:
            parent_text = elem.parent.get_text(strip=True)
            # Extract just the CEU sentence
            if len(parent_text) < 300:
                details["ce_credits"] = parent_text
                break

    # Extract description from meta tag
    meta_desc = soup.find("meta", {"name": "description"})
    if meta_desc:
        details["description"] = meta_desc.get("content", "")

    # Extract target audience
    for heading in soup.find_all(["h2", "h3"]):
        text = heading.get_text(strip=True)
        if "who should" in text.lower() or "target audience" in text.lower():
            next_elem = heading.find_next(["p", "ul", "div"])
            if next_elem:
                audience = next_elem.get_text(strip=True)
                if audience and len(audience) < 500:
                    details["target_audience"] = audience
                    break

    return details


def export_to_csv(courses_data: list[dict], filename: str) -> None:
    """Export course data to CSV file."""
    if not courses_data:
        print("No data to export")
        return

    # Define CSV columns
    fieldnames = [
        "title",
        "type",
        "url",
        "datetime",
        "duration",
        "level",
        "target_audience",
        "ce_credits",
        "price_non_member",
        "price_member",
        "description",
        "instructor",
        "topic",
    ]

    with open(filename, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()

        for course in courses_data:
            # Flatten pricing data
            pricing = course.get("pricing", {})
            row = {
                "title": course.get("title", ""),
                "type": course.get("type", ""),
                "url": course.get("url", ""),
                "datetime": course.get("datetime", ""),
                "duration": course.get("duration_info", ""),
                "level": course.get("level", ""),
                "target_audience": course.get("target_audience", ""),
                "ce_credits": course.get("ce_credits", ""),
                "price_non_member": pricing.get("Non-Member", ""),
                "price_member": pricing.get("Member", ""),
                "description": course.get("description", ""),
                "instructor": course.get("instructor", ""),
                "topic": course.get("topic", ""),
            }
            writer.writerow(row)

    print(f"Exported {len(courses_data)} courses to {filename}")


if __name__ == "__main__":
    url = "https://www.ama.org/topics/"

    print("Getting topics...\n")
    topics = get_topics(url)

    print(f"Found {len(topics)} unique topics:\n")
    for i, (name, topic_url) in enumerate(topics, 1):
        print(f"{i}. {name}")

    # Get courses from first topic
    if topics:
        first_topic_name, first_topic_url = topics[0]
        print(f"\n\n{'=' * 80}")
        print(f"Scraping courses from: {first_topic_name}")
        print("=" * 80 + "\n")

        courses = get_courses_from_topic(first_topic_url)
        print(f"Found {len(courses)} courses on first page")
        print(f"Fetching detailed metadata for each course...\n")

        # Collect all course data with details
        all_courses_data = []
        for i, course in enumerate(courses, 1):
            print(f"[{i}/{len(courses)}] {course['title']}")

            try:
                details = get_course_details(course["url"])
                # Merge basic info with details
                course_data = {
                    **course,
                    **details,
                    "topic": first_topic_name,
                }
                all_courses_data.append(course_data)
            except Exception as e:
                print(f"    Error fetching details: {e}")
                # Add course with basic info only
                all_courses_data.append({**course, "topic": first_topic_name})

        # Export to CSV
        print(f"\n{'=' * 80}\n")
        export_to_csv(all_courses_data, "ama_courses.csv")
        print("\nPreview of first 3 courses:")
        print("=" * 80 + "\n")

        # Show preview
        for i, course in enumerate(all_courses_data[:3], 1):
            print(f"{i}. {course['title']}")
            print(f"   Type: {course['type']}")
            print(f"   URL: {course['url']}")
            if course.get("datetime"):
                print(f"   Date/Time: {course['datetime']}")
            if course.get("level"):
                print(f"   Level: {course['level']}")
            if course.get("pricing"):
                pricing_str = ", ".join([f"{label}: {price}" for label, price in course["pricing"].items()])
                print(f"   Pricing: {pricing_str}")
            print()
