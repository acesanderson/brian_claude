---
name: batch-dispatch
description: Orchestrates parallel, isolated execution of a skill across a list of inputs.
---

## Usage
/batch-dispatch <skill_name> <list_of_inputs> <instruction_template> [--timeout SECONDS] [--max-workers N]

## Arguments
- `skill_name`: Name of the skill to execute in parallel
- `list_of_inputs`: JSON array of inputs (e.g., `'["url1", "url2"]'`)
- `instruction_template`: Jinja2 template for task instructions (use `{{ item }}` for current input)
- `--timeout SECONDS`: Optional. Timeout per task in seconds (default: 600 = 10 minutes)
- `--max-workers N`: Optional. Maximum concurrent workers (default: 5)

## Examples

Basic usage:
```bash
/batch-dispatch catalog-scraper '["https://site1.com", "https://site2.com"]' "Scrape the catalog from {{ item }}"
```

With custom timeout (5 minutes per task):
```bash
/batch-dispatch catalog-scraper '["https://site1.com", "https://site2.com"]' "Scrape {{ item }}" --timeout 300
```

With limited concurrency:
```bash
/batch-dispatch my-skill '["a", "b", "c", "d"]' "Process {{ item }}" --max-workers 2
```

## Behavior

1. **Parallel Execution**: Spawns isolated Claude instances for each input (up to max-workers concurrent)
2. **Result Collection**: Each worker saves structured data to `result.json` in its task directory
3. **Cleanup**: After completion, moves all artifacts (JSON, XLSX, MD, CSV) to `batch_results_<timestamp>/` in CWD
4. **Temp Cleanup**: Automatically deletes temporary `batch_runs/` directory

## Output

Final artifacts are saved to `batch_results_YYYYMMDD_HHMMSS/` containing:
- All output files from successful tasks
- `summary.json` with aggregated results and status for each task

## Important Notes

- Workers run with `--dangerously-skip-permissions` (auto-approve all actions)
- Each worker must create `result.json` with structured data for aggregation
- Timeout applies per task, not to the entire batch
- Failed tasks don't block successful ones

## Implementation
This skill delegates to a Python script that spawns parallel `claude` subprocesses.
It uses `uv` to manage the execution environment ephemerally.

Steps:
1. Locate the `batch_runner.py` script in the `references/` sibling directory
2. Run it using `uv run` with all provided arguments

```bash
#!/bin/bash
# Execute batch runner via uv
SKILL_DIR="$HOME/.claude/skills/batch-dispatch"
SCRIPT_PATH="$SKILL_DIR/references/batch_runner.py"

# Pass all arguments to the Python script
uv run "$SCRIPT_PATH" "$@"
```
