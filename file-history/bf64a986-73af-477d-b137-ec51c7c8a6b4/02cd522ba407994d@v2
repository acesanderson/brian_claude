from __future__ import annotations

import asyncio
from pathlib import Path

import pandas as pd
from rich.console import Console
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TaskProgressColumn

from headwater_client.client.headwater_client_async import HeadwaterAsyncClient
from headwater_api.classes import CuratorRequest, CuratorResponse


console = Console()


def parse_list_file(file_path: Path) -> list[dict]:
    """
    Parse list.txt and extract skill/industry/country/language data.
    """
    queries = []

    with open(file_path) as f:
        lines = f.readlines()

    for line_num, line in enumerate(lines, start=1):
        line = line.strip()
        if not line:
            continue

        parts = line.split("\t")
        if len(parts) < 2:
            console.print(f"[yellow]Skipping line {line_num}: {line}[/yellow]")
            continue

        skill = parts[0].strip()
        industry = parts[1].strip()
        countries = parts[2].strip() if len(parts) > 2 else ""
        language = parts[3].strip() if len(parts) > 3 else ""

        query_string = f"{skill} ({industry})"

        queries.append({
            "skill": skill,
            "industry": industry,
            "countries": countries,
            "language": language,
            "query": query_string,
            "line_num": line_num
        })

    return queries


async def fetch_recommendations(
    client: HeadwaterAsyncClient,
    query_data: dict
) -> list[dict]:
    """
    Fetch course recommendations for a single query.
    """
    try:
        request = CuratorRequest(
            query_string=query_data["query"],
            k=5,
            n_results=30,
            model_name="bge",
            cached=True
        )

        response: CuratorResponse = await client.curator.curate(request)

        results = []
        for result in response.results:
            results.append({
                "skill": query_data["skill"],
                "industry": query_data["industry"],
                "countries": query_data["countries"],
                "language": query_data["language"],
                "query": query_data["query"],
                "course_title": result.id,
                "relevance_score": result.score
            })

        return results

    except Exception as e:
        console.print(f"[red]Error processing {query_data['query']}: {e}[/red]")
        return []


async def fetch_batch(
    client: HeadwaterAsyncClient,
    batch: list[dict],
    progress: Progress,
    task_id
) -> list[dict]:
    """
    Fetch recommendations for a batch of queries in parallel.
    """
    tasks = [fetch_recommendations(client, query_data) for query_data in batch]
    results = await asyncio.gather(*tasks)

    # Flatten results
    all_results = []
    for result_list in results:
        all_results.extend(result_list)
        progress.update(task_id, advance=1)

    return all_results


async def generate_recommendations(batch_size: int = 15):
    """
    Generate course recommendations for all skill/industry pairs in list.txt.
    """
    console.print("[cyan]Starting recommendation generation...[/cyan]")

    # Parse list.txt
    list_file = Path(__file__).parent / "list.txt"
    queries = parse_list_file(list_file)

    console.print(f"[green]Parsed {len(queries)} skill/industry pairs[/green]")

    # Create batches
    batches = [queries[i:i + batch_size] for i in range(0, len(queries), batch_size)]
    console.print(f"[green]Created {len(batches)} batches of size {batch_size}[/green]")

    all_results = []

    # Process batches
    async with HeadwaterAsyncClient() as client:
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TaskProgressColumn(),
            console=console
        ) as progress:
            task = progress.add_task(
                "[cyan]Processing queries...",
                total=len(queries)
            )

            for batch_num, batch in enumerate(batches, start=1):
                console.print(f"[yellow]Processing batch {batch_num}/{len(batches)}[/yellow]")
                batch_results = await fetch_batch(client, batch, progress, task)
                all_results.extend(batch_results)

    # Create DataFrame
    df = pd.DataFrame(all_results)

    # Save to XLSX
    output_file = Path(__file__).parent / "course_recommendations.xlsx"
    df.to_excel(output_file, index=False)

    console.print(f"\n[green]Successfully generated {len(all_results)} recommendations[/green]")
    console.print(f"[green]Total skill/industry pairs: {len(queries)}[/green]")
    console.print(f"[green]Saved to: {output_file}[/green]")

    # Summary stats
    if len(queries) > 0 and len(all_results) > 0:
        console.print(f"\n[cyan]Summary:[/cyan]")
        console.print(f"  Average recommendations per query: {len(all_results) / len(queries):.1f}")
        console.print(f"  Unique courses recommended: {df['course_title'].nunique()}")
    elif len(queries) > 0:
        console.print("\n[yellow]No results generated. Check API connectivity.[/yellow]")
    else:
        console.print("\n[yellow]No queries were parsed. Check your list.txt format.[/yellow]")

    return df


if __name__ == "__main__":
    asyncio.run(generate_recommendations())
